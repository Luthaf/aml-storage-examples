{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfd345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ae5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from equistore import Labels, TensorBlock, TensorMap\n",
    "from torch_builder import TensorBuilder\n",
    "import ase.io\n",
    "from itertools import product\n",
    "from torch_cg import ClebschGordanReal\n",
    "from torch_hamiltonians import fix_pyscf_l1, dense_to_blocks, blocks_to_dense, couple_blocks, decouple_blocks, hamiltonian_features\n",
    "import matplotlib.pyplot as plt\n",
    "from rascal.representations import SphericalExpansion\n",
    "import copy\n",
    "from ase.units import Hartree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e301ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'/Users//new-hamiltonian/equistore-examples')\n",
    "from utils.librascal import  RascalSphericalExpansion, RascalPairExpansion\n",
    "from utils.acdc_mini import acdc_standardize_keys, cg_increment, cg_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db09b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ase.io.read(\"../data/hamiltonian/water-hamiltonian/water_coords_1000.xyz\",\":200\")\n",
    "for f in frames:\n",
    "    f.cell = [100,100,100]\n",
    "    f.positions += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "292e1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jorbs = json.load(open('data/water-hamiltonian/water_orbs.json', \"r\"))\n",
    "jorbs = json.loads(json.load(open('../data/hamiltonian/water-hamiltonian/water_orbs.json', \"r\")))\n",
    "orbs = {}\n",
    "zdic = {\"O\" : 8, \"H\":1}\n",
    "for k in jorbs:\n",
    "    orbs[zdic[k]] = jorbs[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aab6a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "hams = np.load(\"../data/hamiltonian/water-hamiltonian/water_saph_orthogonal.npy\", allow_pickle=True)[:len(frames)]\n",
    "# NO NEED TO CORRECT L1 ORDER FOR SAPH ORTHOGONALIZED MATRICES...\n",
    "#for i, f in enumerate(frames):\n",
    "#    hams[i] = fix_pyscf_l1(hams[i], f, orbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "754797bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ClebschGordanReal(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17e9fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss functions\n",
    "def mse_full(fock, pred_blocks, frame, orbs):\n",
    "    predicted = blocks_to_dense(decouple_blocks(pred_blocks), frame, orbs)\n",
    "    mse_loss = torch.empty(len(frame))\n",
    "    for i in range(len(frame)):\n",
    "        mse_loss[i] = (torch.linalg.norm(fock[i]-predicted[i]))**2/len(fock[i])\n",
    "        #print(\"from mse\", i, fock[i], mse_loss[i])\n",
    "    return torch.mean(mse_loss)*(Hartree)**2\n",
    "\n",
    "def mse_eigvals(fock, pred_blocks, frame, orbs):\n",
    "    predicted = blocks_to_dense(decouple_blocks(pred_blocks), frame, orbs)\n",
    "    evanorm = torch.empty(len(frame))\n",
    "    for i in range(len(frame)):\n",
    "        evanorm[i] = torch.mean((torch.linalg.eigvalsh(fock[i]) - torch.linalg.eigvalsh(predicted[i]))**2)/len(fock[i])\n",
    "    return torch.mean(evanorm)*(Hartree)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "196167ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feats(feat, all_blocks=True): \n",
    "    all_norm = 0\n",
    "    for block_idx, block in feat: \n",
    "        block_norm = np.linalg.norm(block.values)\n",
    "#         print(block_idx, block_norm)\n",
    "        all_norm += block_norm**2\n",
    "    normalized_blocks=[]\n",
    "    for block_idx, block in feat: \n",
    "        newblock = TensorBlock(\n",
    "                        values=block.values/np.sqrt(all_norm ),\n",
    "                        samples=block.samples,\n",
    "                        components=block.components,\n",
    "                        properties= block.properties)\n",
    "                    \n",
    "        normalized_blocks.append(newblock) \n",
    "        \n",
    "    norm_feat = TensorMap(feat.keys, normalized_blocks)\n",
    "    return norm_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ad712",
   "metadata": {},
   "source": [
    "## Manipulate Hamiltonian into blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "461e38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = dense_to_blocks(hams, frames, orbs)\n",
    "fock_bc = couple_blocks(blocks, cg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8cfe3",
   "metadata": {},
   "source": [
    "## Feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13064b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rascal_hypers = {\n",
    "    \"interaction_cutoff\": 4,\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"max_radial\": 12,\n",
    "    \"max_angular\": 8,\n",
    "    \"gaussian_sigma_constant\" : 0.25,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"compute_gradients\":  False,\n",
    "}\n",
    "\n",
    "spex = RascalSphericalExpansion(rascal_hypers)\n",
    "rhoi = spex.compute(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc39e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = RascalPairExpansion(rascal_hypers)\n",
    "gij = pairs.compute(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abf74c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1i = acdc_standardize_keys(rhoi)\n",
    "rho1i.keys_to_properties(['species_neighbor'])\n",
    "gij =  acdc_standardize_keys(gij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a666711",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho2i = cg_increment(rho1i, rho1i, lcut=2, other_keys_match=[\"species_center\"], clebsch_gordan=cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4565f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rho3i = cg_increment(rho2i, rho1i, lcut=2, other_keys_match=[\"species_center\"], clebsch_gordan=cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bdcb6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1ij = cg_increment(rho1i, gij, lcut=2, other_keys_match=[\"species_center\"], clebsch_gordan=cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c5d9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rho2ij = cg_increment(rho2i, gij, lcut=2, other_keys_match=[\"species_center\"], clebsch_gordan=cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b29eb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_feats = hamiltonian_features(rho2i, rho1ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6739d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ham_feats = normalize_feats(ham_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8c8bc",
   "metadata": {},
   "source": [
    "# Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc7c1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, coupled_blocks, features, weights=None, intercepts=None):\n",
    "        super().__init__()\n",
    "        self.coupled_blocks = coupled_blocks\n",
    "        self.features = features\n",
    "        self.weights = {}\n",
    "        if weights==None:\n",
    "            for idx_fock, block_fock in self.coupled_blocks:\n",
    "                block_type, ai, ni, li, aj, nj, lj, L = idx_fock\n",
    "                parity= (-1)**(li+lj+L)\n",
    "                size = self.features.block(block_type=block_type, spherical_harmonics_l=L,inversion_sigma=parity, \n",
    "                                       species_center=ai, species_neighbor=aj).values.shape[2]\n",
    "                #self.weights[idx_fock] = torch.nn.Parameter(torch.zeros(size, dtype=torch.float64))\n",
    "                self.weights[idx_fock] = torch.nn.Parameter(torch.randn(size, dtype=torch.float64))\n",
    "            \n",
    "        else: \n",
    "            self.weights = weights\n",
    "        \n",
    "        self.intercepts = {}\n",
    "        if intercepts is None:\n",
    "            for idx_fock, block_fock in self.coupled_blocks:\n",
    "                block_type, ai, ni, li, aj, nj, lj, L = idx_fock\n",
    "                parity= (-1)**(li+lj+L)\n",
    "                if L==0 and parity==1 and block_type==0:\n",
    "                    self.intercepts[idx_fock] = torch.nn.Parameter(torch.randn(1, dtype=torch.float64))\n",
    "                else:\n",
    "                    self.intercepts[idx_fock] = 0\n",
    "        else:\n",
    "            self.intercepts = intercepts\n",
    "         \n",
    "    def forward(self, features):\n",
    "        k = []\n",
    "        pred_blocks = []\n",
    "        for (idx, wts) in self.weights.items():\n",
    "            #print(wts)\n",
    "            block_type, ai, ni, li, aj, nj, lj, L = idx\n",
    "            k.append(list(idx))\n",
    "            parity= (-1)**(li+lj+L)\n",
    "            X = features.block(block_type=block_type, spherical_harmonics_l=L,inversion_sigma=parity, \n",
    "                                   species_center=ai, species_neighbor=aj)\n",
    "            X_new = torch.from_numpy(X.values.reshape(-1, X.values.shape[2]))\n",
    "            #print(idx, wts.shape, X.values.shape, X_new.shape)\n",
    "            Y = X_new @ wts + self.intercepts[idx]\n",
    "            \n",
    "            newblock = TensorBlock(\n",
    "                        values=Y.reshape((-1, 2 * L + 1, 1)),\n",
    "                        samples=X.samples,\n",
    "                        components=[Labels(\n",
    "                            [\"mu\"], np.asarray(range(-L, L + 1), dtype=np.int32).reshape(-1, 1)\n",
    "                        )],\n",
    "                        properties= Labels([\"values\"], np.asarray([[0]], dtype=np.int32))\n",
    "                    )\n",
    "            pred_blocks.append(newblock) \n",
    "        \n",
    "        keys = Labels(('block_type', 'a_i', 'n_i', 'l_i', 'a_j', 'n_j', 'l_j', 'L'), np.asarray(k, dtype=np.int32))\n",
    "        pred_fock = TensorMap(keys, pred_blocks)\n",
    "        return(pred_fock)\n",
    "        ### add direct eigenvalue prediction here as well\n",
    "    \n",
    "    def parameters(self):\n",
    "        for idx, wts in self.weights.items():\n",
    "            yield wts\n",
    "        for idx, wts in self.intercepts.items():\n",
    "            if type(wts) is not int:\n",
    "                yield wts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bf5cc",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# For single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5dbeb35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i_frame = frames[0]\n",
    "i_ham = hams[0] \n",
    "\n",
    "i_feats = ham_feats.slice(Labels(names=[\"structure\"], values=np.asarray(range(1), dtype=np.int32).reshape(-1,1)) )\n",
    "i_focks = fock_bc.slice(Labels(names=[\"structure\"], values=np.asarray(range(1), dtype=np.int32).reshape(-1,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "044d1f5c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm_i_feats = normalize_feats(i_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf945f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing the model with weights from equistore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "133da935",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights = np.load('model_weights.npy', allow_pickle=True)[()]\n",
    "intercepts = np.load('model_intercepts.npy', allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6e2e675",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model contains 8 parameters\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 256 is different from 5184)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-697224629414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"the model contains {len(list(model.parameters()))} parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-7c4f7f2600b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#print(idx, wts.shape, X.values.shape, X_new.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mwts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mwts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 256 is different from 5184)"
     ]
    }
   ],
   "source": [
    "model = LinearModel(i_focks, i_feats, weights=weights, intercepts=intercepts)\n",
    "print(f\"the model contains {len(list(model.parameters()))} parameters\")\n",
    "\n",
    "pred = model(i_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117810f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = mse_full([torch.from_numpy(i_ham.astype(np.float64))], pred, [i_frame], orbs)\n",
    "print(torch.sqrt(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a7f25f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Training with loss on full Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456cbe7",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearModel(i_focks, norm_i_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15000, gamma=0.01)\n",
    "\n",
    "all_losses = []\n",
    "for epoch in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(norm_i_feats)\n",
    "    loss = mse_full([torch.from_numpy(i_ham.astype(np.float64))], pred, [i_frame], orbs)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "#     scheduler.step()\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bba86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(all_losses)\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"$MSE_{full}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf654b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = model(norm_i_feats)\n",
    "mse_full([torch.from_numpy(i_ham.astype(np.float64))], pred, [i_frame], orbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebedc2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training with loss on eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac120e84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = LinearModel(i_focks, i_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.01)\n",
    "\n",
    "eigval_losses = []\n",
    "for epoch in range(30000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(i_feats[0])\n",
    "    eigval_loss = mse_eigvals([torch.from_numpy(i_ham.astype(np.float64))], pred, [i_frame], orbs)\n",
    "    eigval_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    eigval_losses.append(eigval_loss.item())\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(epoch, eigval_loss.item())\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfda8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(eigval_losses)\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"$MSE_{\\epsilon}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d4008",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_coupled = model(ham_feats)\n",
    "rmse_full = torch.sqrt(mse_full([torch.from_numpy(i_ham.astype(np.float64))], pred, [i_frame], orbs))\n",
    "print(rmse_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef93952",
   "metadata": {},
   "source": [
    "# Train and test on multiple frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36370cdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77c7f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(frames)\n",
    "ntrain = int(N*0.8)\n",
    "train_frames = frames[:ntrain]\n",
    "train_hams = hams[:ntrain]\n",
    "train_feats = norm_ham_feats.slice(Labels(names=[\"structure\"], values=np.asarray(range(ntrain), dtype=np.int32).reshape(-1,1)) )\n",
    "train_focks = fock_bc.slice(Labels(names=[\"structure\"], values=np.asarray(range(ntrain), dtype=np.int32).reshape(-1,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c58935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frames = frames[ntrain:N]\n",
    "test_hams = hams[ntrain:N]\n",
    "test_feats = norm_ham_feats.slice(Labels(names=[\"structure\"], values=np.asarray(range(ntrain,N), dtype=np.int32).reshape(-1,1)) )\n",
    "test_focks = fock_bc.slice(Labels(names=[\"structure\"], values=np.asarray(range(ntrain,N), dtype=np.int32).reshape(-1,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3f58021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 352.81134033203125\n",
      "50 0.7855337262153625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6492e5b655fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_hams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3998427f55f1>\u001b[0m in \u001b[0;36mmse_full\u001b[0;34m(fock, pred_blocks, frame, orbs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loss functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmse_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblocks_to_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecouple_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/ceriotti/lavoro/code/equistore-examples/equistore-pytorch/torch_hamiltonians.py\u001b[0m in \u001b[0;36mblocks_to_dense\u001b[0;34m(blocks, frames, orbs)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mham\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mblock_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mham\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjslice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mblock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mham\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mblock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mki_offset\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mkj_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LinearModel(train_focks, train_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.8)\n",
    "\n",
    "all_losses = []\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_feats)\n",
    "    loss = mse_full(torch.from_numpy(train_hams.astype(np.float64)), pred, train_frames, orbs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(epoch, loss.item()) \n",
    "#     if loss.item <1e-15: \n",
    "#         break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed648e-d95d-4e6b-a228-4d355c775a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(train_focks, train_feats)\n",
    "optimizer = torch.optim.LBFGS(\n",
    "        model.parameters(),\n",
    "        lr=0.8,  line_search_fn=\"strong_wolfe\",\n",
    "        history_size=256,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f06d8b7e-0004-4938-a879-dca0d01355ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3f6232ef734a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mall_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "for epoch in range(300):\n",
    "    def single_step():\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(train_feats)\n",
    "        loss = mse_full(torch.from_numpy(train_hams.astype(np.float64)), pred, train_frames, orbs)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    loss = optimizer.step(single_step)\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch, loss.item()) \n",
    "#     if loss.item <1e-15: \n",
    "#         break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(np.sqrt(all_losses))\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"$RMSE_{full}$\")\n",
    "print(np.sqrt(all_losses[-1]), \"eV rmse on TRAIN H prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = model(norm_ham_feats.slice(Labels(names=[\"structure\"], values=np.asarray(range(N), dtype=np.int32).reshape(-1,1)) ))\n",
    "all_loss = mse_full(torch.from_numpy(hams[:N].astype(np.float64)), pred_all, frames[:N], orbs)\n",
    "print(torch.sqrt(all_loss), \"eV rmse on ALL H prediction\")\n",
    "# test_loss_eigvals = mse_eigvals(torch.from_numpy(test_hams.astype(np.float64)), pred_test, test_frames, orbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TEMPORARY FIX to reindex just the test frames \n",
    "pred_test = model(test_feats)\n",
    "bvalues = []\n",
    "for i, b in pred_test:\n",
    "    newblock = TensorBlock(\n",
    "                        values=b.values,\n",
    "                        samples=pred.block(i).samples[:len(b.values)],\n",
    "                        components=b.components,\n",
    "                        properties= b.properties)\n",
    "                    \n",
    "    bvalues.append(newblock) \n",
    "        \n",
    "reindexed_pred_test  = TensorMap(test_focks.keys, bvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340609fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexed_pred_test.block(0).samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = mse_full(torch.from_numpy(test_hams.astype(np.float64)), reindexed_pred_test, test_frames, orbs)\n",
    "test_loss_eigvals = mse_eigvals(torch.from_numpy(test_hams.astype(np.float64)), reindexed_pred_test, test_frames, orbs)\n",
    "print(torch.sqrt(test_loss),  \"eV rmse on TEST H prediction\")\n",
    "print(torch.sqrt(test_loss_eigvals),  \"eV rmse on TEST eigen prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d86a47",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training on eigenvalue loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b848afac-b445-4aab-9749-196bc10af61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(train_focks, train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7ad2b9cb-37c2-4836-b106-06c2ad9bc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.5)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)\n",
    "optimizer = torch.optim.LBFGS(\n",
    "        model.parameters(),\n",
    "        lr=0.8,  line_search_fn=\"strong_wolfe\",\n",
    "        history_size=256, tolerance_grad=1e-12, tolerance_change=1e-12\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "69e553a5-8300-47fa-8dcc-34ccd4e09623",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "82631bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9684617655002512e-05 1.968262040463742e-05 0.0397777296602726\n",
      "1 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "2 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "3 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "4 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "5 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "6 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "7 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "8 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n",
      "9 1.968262040463742e-05 1.968262040463742e-05 0.0397777296602726\n"
     ]
    }
   ],
   "source": [
    "all_eigval_losses = []\n",
    "all_losses = []\n",
    "combined_loss = []\n",
    "for epoch in range(10):\n",
    "    eva_loss = 0\n",
    "    full_loss = 0\n",
    "    def single_step():\n",
    "        global eva_loss, full_loss\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(train_feats)\n",
    "        eva_loss = mse_eigvals(torch.from_numpy(train_hams.astype(np.float64)), pred, train_frames, orbs)\n",
    "        full_loss = mse_full(torch.from_numpy(train_hams.astype(np.float64)), pred, train_frames, orbs)\n",
    "        loss_combined = 1e0*eva_loss + 0e-1*full_loss\n",
    "        loss_combined.backward()\n",
    "        return loss_combined\n",
    "    \n",
    "    loss_combined = optimizer.step(single_step)\n",
    "    #scheduler.step()\n",
    "    \n",
    "    all_eigval_losses.append(eva_loss.item())\n",
    "    all_losses.append(full_loss.item())\n",
    "    combined_loss.append(loss_combined.item())\n",
    "    \n",
    "    if epoch % 1== 0:\n",
    "        print(epoch, loss_combined.item(), eva_loss.item(), full_loss.item())\n",
    "        #print(\"gradients\") \n",
    "        #for k, w in model.weights.items():  \n",
    "        #    print(k, np.linalg.norm(w.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "291dcf28-349b-4413-9e17-09a0fe11624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for k,w in model.weights.items():\n",
    "        w-=w.grad*1e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "487a5c7e-ed26-475e-9d8b-2a617ced1de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4735,  0.1898, -5.3075,  ..., -0.2122, -0.8850,  0.7704],\n",
       "       dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w-w.grad*1e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11a9b6-4416-456b-a07c-0fa74ba18118",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.6183997761108913e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4503a3cc-b3ca-417f-83f0-bbf1e8672daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 8, 2, 0, 8, 2, 0, 0): Parameter containing:\n",
       " tensor([-0.9673], dtype=torch.float64, requires_grad=True),\n",
       " (0, 8, 2, 0, 8, 2, 1, 1): 0,\n",
       " (0, 8, 2, 1, 8, 2, 1, 0): Parameter containing:\n",
       " tensor([0.6027], dtype=torch.float64, requires_grad=True),\n",
       " (0, 8, 2, 1, 8, 2, 1, 2): 0,\n",
       " (2, 1, 1, 0, 8, 2, 0, 0): 0,\n",
       " (2, 1, 1, 0, 8, 2, 1, 1): 0,\n",
       " (0, 1, 1, 0, 1, 1, 0, 0): Parameter containing:\n",
       " tensor([-0.3331], dtype=torch.float64, requires_grad=True),\n",
       " (1, 1, 1, 0, 1, 1, 0, 0): 0}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "774c2c6e-41eb-465c-bbf1-6cfcc71a065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([-0.2395, -1.7251, -1.4860,  ...,  1.1424, -1.2006,  0.8711],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4167, -1.9908, -0.4233,  ..., -1.2525,  0.9108, -0.1376],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2519,  0.4813,  1.4748,  ..., -0.4117,  0.5766,  0.4966],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.4304, -0.7898,  1.5848,  ..., -0.4800, -0.8939, -2.0150],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ -2.9705, -11.2705, -19.8464,  ...,  -0.3524,   0.3452,   0.6273],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 2.2491,  2.1953,  9.8662,  ...,  0.1785,  0.6699, -1.3144],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.0288,  0.5874, -0.3370,  ..., -0.2983,  0.2164, -0.8538],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.8454,  0.6493, -4.9420,  ..., -0.4703,  1.0781,  0.1765],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.9497], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.6101], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3454], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3f90eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$RMSE_{\\\\epsilon}$')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(np.sqrt(all_eigval_losses))\n",
    "plt.loglog(np.sqrt(all_losses))\n",
    "plt.loglog(np.sqrt(combined_loss), 'g.')\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"$RMSE_{\\epsilon}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2b447789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model(test_feats)\n",
    "bvalues = []\n",
    "for i, b in pred_test:\n",
    "    newblock = TensorBlock(\n",
    "                        values=b.values,\n",
    "                        samples=pred.block(i).samples[:len(b.values)],\n",
    "                        components=b.components,\n",
    "                        properties= b.properties)\n",
    "                    \n",
    "    bvalues.append(newblock) \n",
    "        \n",
    "reindexed_pred_test  = TensorMap(test_focks.keys, bvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "921b4e03-8551-462d-8b11-bb137720ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = blocks_to_dense(decouple_blocks(reindexed_pred_test), frames, orbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "167ef78c-b384-4e73-84b5-1d25921c8610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2692, -0.6132, -0.5704, -0.4968,  0.1497,  0.2258],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvalsh(torch.from_numpy(test_hams[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f37ccee3-f17c-4657-8777-b8663a94cdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2684, -0.6132, -0.5695, -0.4968,  0.1493,  0.2257],\n",
       "       grad_fn=<LinalgEighBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvalsh(dense[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ec19b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.3165, grad_fn=<SqrtBackward0>) eV rmse on TEST H prediction\n",
      "tensor(0.1699, grad_fn=<SqrtBackward0>) eV rmse on TEST eigen prediction\n"
     ]
    }
   ],
   "source": [
    "test_loss = mse_full(torch.from_numpy(test_hams.astype(np.float64)), reindexed_pred_test, test_frames, orbs)\n",
    "test_loss_eigvals = mse_eigvals(torch.from_numpy(test_hams.astype(np.float64)), reindexed_pred_test, test_frames, orbs)\n",
    "print(torch.sqrt(test_loss),  \"eV rmse on TEST H prediction\")\n",
    "print(torch.sqrt(test_loss_eigvals),  \"eV rmse on TEST eigen prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4429de6",
   "metadata": {},
   "source": [
    "## Train first on MSE_full and then retrain on MSE_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ade88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearModel(train_focks, train_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.8)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)\n",
    "\n",
    "all_losses = []\n",
    "for epoch in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_feats)\n",
    "    loss = mse_full(torch.from_numpy(train_hams.astype(np.float64)), pred, train_frames, orbs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc02e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eigval_losses = []\n",
    "all_ham_losses = []\n",
    "combined_loss = []\n",
    "\n",
    "for epoch in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    re_pred = model(train_feats)\n",
    "    loss1 = mse_full(torch.from_numpy(train_hams.astype(np.float64)), re_pred, train_frames, orbs)\n",
    "    loss2 = mse_eigvals(torch.from_numpy(train_hams.astype(np.float64)), re_pred, train_frames, orbs)\n",
    "    loss_combined = loss1 + loss2\n",
    "    loss_combined.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    \n",
    "    all_eigval_losses.append(loss2.item())\n",
    "    all_ham_losses.append(loss1.item())\n",
    "    combined_loss.append(loss_combined.item())\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        print(\"Epoch:\", epoch, \"combined:\", loss_combined.item(), \"MSE_full:\", loss1.item(), \"MSE_eva:\", loss2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff11c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model(test_feats)\n",
    "bvalues = []\n",
    "for i, b in pred_test:\n",
    "    newblock = TensorBlock(\n",
    "                        values=b.values,\n",
    "                        samples=pred.block(i).samples[:len(b.values)],\n",
    "                        components=b.components,\n",
    "                        properties= b.properties)\n",
    "                    \n",
    "    bvalues.append(newblock) \n",
    "        \n",
    "reindexed_pred_test  = TensorMap(test_focks.keys, bvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = mse_full(torch.from_numpy(test_hams.astype(np.float64)), reindexed_pred_test, test_frames, orbs)\n",
    "test_loss_eigvals = mse_eigvals(torch.from_numpy(test_hams.astype(np.float64)), reindexed_pred_test, test_frames, orbs)\n",
    "print(torch.sqrt(test_loss),  \"eV rmse on TEST H prediction\")\n",
    "print(torch.sqrt(test_loss_eigvals),  \"eV rmse on TEST eigen prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b0143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "9b1dab49005db54eeaf19407b770a132388229704ecb91b436b854691f0d31ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
